{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "t.set_num_threads(8)\n",
    "import pandas as pd\n",
    "from train import train\n",
    "from models import Transformer, AoT\n",
    "from utils import generate_data, power_unif_law\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:26<00:00,  8.61s/it]\n",
      "100%|██████████| 10/10 [01:35<00:00,  9.58s/it]\n",
      "100%|██████████| 10/10 [06:36<00:00, 39.66s/it]\n",
      "100%|██████████| 10/10 [06:42<00:00, 40.29s/it]\n",
      "100%|██████████| 10/10 [10:31<00:00, 63.10s/it]\n",
      "100%|██████████| 10/10 [10:30<00:00, 63.03s/it]\n",
      "100%|██████████| 10/10 [15:16<00:00, 91.65s/it]\n",
      "100%|██████████| 10/10 [14:59<00:00, 89.93s/it]\n",
      "100%|██████████| 10/10 [16:31<00:00, 99.13s/it]t]\n",
      "100%|██████████| 10/10 [18:12<00:00, 109.24s/it]\n",
      "100%|██████████| 5/5 [1:42:22<00:00, 1228.50s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\"\"\" Experiment 1. Scaling laws on H with fixed d=d_head. \"\"\"\n",
    "t.manual_seed(2222)\n",
    "\n",
    "# Model parameters.\n",
    "N = 50\n",
    "nb_layers = 5 #Depth of the network\n",
    "nb_head = 1\n",
    "n_gram = 3\n",
    "context_window = n_gram\n",
    "\n",
    "# Distribution parameters.\n",
    "alphas = [1, 1, 1]\n",
    "nb_tokens=[100, 100, 1]\n",
    "pi = power_unif_law(alphas, nb_tokens, N)\n",
    "\n",
    "# Training parameters.\n",
    "batch_size=2**10\n",
    "num_batch=1000\n",
    "lr=5e-4\n",
    "epochs=10\n",
    "repetition = 2\n",
    "Data = generate_data(batch_size=batch_size, num_batch=num_batch, pi=pi, context_window=context_window)\n",
    "\n",
    "# Scaling parameters\n",
    "d = 10\n",
    "\n",
    "d_head=d \n",
    "\n",
    "mean_accuracy = []\n",
    "para_list = []\n",
    "N_list = []\n",
    "d_list = []\n",
    "d_head_list = []\n",
    "\n",
    "for para in tqdm([1, 6, 11, 16, 21]):\n",
    "    accuracy = 0\n",
    "\n",
    "    for _ in range(repetition):\n",
    "        model = AoT(d, N, nb_layers, para, d_head, nb_head, context_window, pi)\n",
    "\n",
    "        dict = train(model, Data, epochs, lr=lr, next_token=True)\n",
    "        acc = sum(dict['Acc'][-101:-1])/100\n",
    "            \n",
    "        accuracy += acc\n",
    "\n",
    "    mean_accuracy.append(accuracy/repetition)\n",
    "    N_list.append(N)\n",
    "    d_list.append(d)\n",
    "    d_head_list.append(d_head)\n",
    "    para_list.append(para)\n",
    "\n",
    "results = {\n",
    "    'acc': mean_accuracy,\n",
    "    'para': para_list,\n",
    "    'N': N_list,\n",
    "    'd': d_list,\n",
    "    'd_head': d_head_list,\n",
    "}\n",
    "\n",
    "# We save the results as a dataframe.\n",
    "data = pd.DataFrame(results)\n",
    "data.to_csv(f'Scaling laws/Data_exp_1_{7}_depth.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:07<00:00, 54.71s/it]\n",
      "100%|██████████| 10/10 [09:13<00:00, 55.38s/it]\n",
      "100%|██████████| 10/10 [14:15<00:00, 85.56s/it]t]\n",
      "100%|██████████| 10/10 [13:44<00:00, 82.43s/it]\n",
      "100%|██████████| 10/10 [14:14<00:00, 85.42s/it]t]\n",
      "100%|██████████| 10/10 [14:48<00:00, 88.84s/it]\n",
      "100%|██████████| 10/10 [17:27<00:00, 104.76s/it]]\n",
      "100%|██████████| 10/10 [18:01<00:00, 108.17s/it]\n",
      "100%|██████████| 10/10 [24:58<00:00, 149.89s/it]]\n",
      "100%|██████████| 10/10 [26:20<00:00, 158.02s/it]\n",
      "100%|██████████| 5/5 [2:42:11<00:00, 1946.38s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\"\"\" Experiment 2. Scaling laws on d_head, with d!=d_head and H (=para) fixed. \"\"\"\n",
    "t.manual_seed(2222)\n",
    "\n",
    "# Model parameters.\n",
    "N = 50\n",
    "d = 10\n",
    "para = 21\n",
    "nb_layers = 5 # Depth of the network\n",
    "nb_head = 1\n",
    "n_gram = 3\n",
    "context_window = n_gram\n",
    "\n",
    "# Distribution parameters.\n",
    "alphas = [1, 1, 1]\n",
    "nb_tokens=[100, 100, 1]\n",
    "pi = power_unif_law(alphas, nb_tokens, N)\n",
    "\n",
    "# Training parameters.\n",
    "batch_size=2**10\n",
    "num_batch=1000\n",
    "lr=5e-4\n",
    "epochs=10\n",
    "repetition = 2\n",
    "Data = generate_data(batch_size=batch_size, num_batch=num_batch, pi=pi, context_window=context_window)\n",
    "\n",
    "# Scaling parameters\n",
    "mean_accuracy = []\n",
    "para_list = []\n",
    "N_list = []\n",
    "d_list = []\n",
    "d_head_list = []\n",
    "for d_head in tqdm([1, 3, 5, 7, 10]):\n",
    "    accuracy = 0\n",
    "\n",
    "    for _ in range(repetition):\n",
    "        model = AoT(d, N, nb_layers, para, d_head, nb_head, context_window, pi)\n",
    "\n",
    "        dict = train(model, Data, epochs, lr=lr, next_token=True)\n",
    "        acc = sum(dict['Acc'][-101:-1])/100\n",
    "        \n",
    "        accuracy += acc\n",
    "\n",
    "    mean_accuracy.append(accuracy/repetition)\n",
    "    N_list.append(N)\n",
    "    d_list.append(d)\n",
    "    d_head_list.append(d_head)\n",
    "    para_list.append(para)\n",
    "\n",
    "results = {\n",
    "    'acc': mean_accuracy,\n",
    "    'para': para_list,\n",
    "    'N': N_list,\n",
    "    'd': d_list,\n",
    "    'd_head': d_head_list,\n",
    "}\n",
    "\n",
    "# We save the results as a dataframe.\n",
    "data = pd.DataFrame(results)\n",
    "data.to_csv(f'Scaling laws/Data_exp_2_depth.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:12<00:00, 31.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0713134765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:46<00:00, 34.66s/it]\n",
      " 20%|██        | 1/5 [10:59<43:57, 659.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16455078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:12<00:00, 61.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.182373046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:06<00:00, 78.63s/it]\n",
      " 40%|████      | 2/5 [34:18<54:43, 1094.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58119140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [20:24<00:00, 122.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:40<00:00, 112.08s/it]\n",
      " 60%|██████    | 3/5 [1:13:23<55:31, 1665.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [20:48<00:00, 124.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3352978515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [17:52<00:00, 107.23s/it]\n",
      " 80%|████████  | 4/5 [1:52:04<32:04, 1924.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [20:48<00:00, 124.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6718212890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:20<00:00, 98.08s/it]\n",
      "100%|██████████| 5/5 [2:29:13<00:00, 1790.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.171162109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:18<00:00, 25.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.140830078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:05<00:00, 24.55s/it]\n",
      " 20%|██        | 1/5 [08:24<33:37, 504.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262548828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:02<00:00, 54.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5894189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:17<00:00, 49.80s/it]\n",
      " 40%|████      | 2/5 [25:44<40:58, 819.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.160009765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:33<00:00, 69.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572939453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [11:41<00:00, 70.19s/it]\n",
      " 60%|██████    | 3/5 [48:59<36:04, 1082.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3535839843750002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:16<00:00, 91.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9320654296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:22<00:00, 92.28s/it]\n",
      " 80%|████████  | 4/5 [1:19:38<23:01, 1381.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.556513671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:29<00:00, 110.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40263671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:28<00:00, 110.88s/it]\n",
      "100%|██████████| 5/5 [1:56:37<00:00, 1399.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30408203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:03<00:00, 24.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1987353515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:05<00:00, 24.59s/it]\n",
      " 20%|██        | 1/5 [08:09<32:37, 489.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3898291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:02<00:00, 60.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98287109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:58<00:00, 59.89s/it]\n",
      " 40%|████      | 2/5 [28:10<45:24, 908.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9610058593750002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:41<00:00, 88.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9741259765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:15<00:00, 85.59s/it]\n",
      " 60%|██████    | 3/5 [57:07<42:53, 1286.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9724560546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:41<00:00, 112.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471435546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:42<00:00, 112.22s/it]\n",
      " 80%|████████  | 4/5 [1:34:32<27:44, 1664.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9471435546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:13<00:00, 127.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:17<00:00, 127.73s/it]\n",
      "100%|██████████| 5/5 [2:17:02<00:00, 1644.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:29<00:00, 20.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0962841796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:28<00:00, 20.85s/it]\n",
      " 20%|██        | 1/5 [06:58<27:53, 418.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.199248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:16<00:00, 79.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2126171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [13:04<00:00, 78.40s/it]\n",
      " 40%|████      | 2/5 [33:18<55:05, 1101.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45463378906249996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:49<00:00, 130.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982763671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [22:03<00:00, 132.33s/it]\n",
      " 60%|██████    | 3/5 [1:17:11<1:00:01, 1800.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6292041015625001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [31:33<00:00, 189.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.468037109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [31:40<00:00, 190.03s/it]\n",
      " 80%|████████  | 4/5 [2:20:26<43:07, 2587.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89357421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [40:48<00:00, 244.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.370390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [41:10<00:00, 247.07s/it]\n",
      "100%|██████████| 5/5 [3:42:25<00:00, 2669.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9461962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:01<00:00, 24.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1841357421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:02<00:00, 24.21s/it]\n",
      " 20%|██        | 1/5 [08:04<32:16, 484.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3803662109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:07<00:00, 96.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593037109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:12<00:00, 97.28s/it]\n",
      " 40%|████      | 2/5 [40:24<1:07:02, 1340.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.284013671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [27:27<00:00, 164.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9460400390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [27:25<00:00, 164.51s/it]\n",
      " 60%|██████    | 3/5 [1:35:17<1:14:24, 2232.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9065380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [29:56<12:50, 256.68s/it]\n",
      " 60%|██████    | 3/5 [2:05:14<1:23:29, 2504.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repetition):\n\u001b[1;32m     86\u001b[0m     model \u001b[38;5;241m=\u001b[39m AoT(d, N, nb_layers, para, d_head, nb_head, context_window, pi)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m101\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     91\u001b[0m     accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "File \u001b[0;32m~/Desktop/Stage Dauphine Code/Learning_Bigram/train.py:58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, epochs, lr, next_token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     57\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 58\u001b[0m     model_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     loss \u001b[38;5;241m=\u001b[39m compute_loss(model, model_logits, batch, ent, loss_fn, next_token)\n\u001b[1;32m     60\u001b[0m     acc \u001b[38;5;241m=\u001b[39m compute_acc(model, model_logits, batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Stage Dauphine Code/Learning_Bigram/models.py:88\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m para_attn, mlp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_seq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_seq):\n\u001b[1;32m     87\u001b[0m     compressed_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_compress(res) \u001b[38;5;241m+\u001b[39m pos \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m!=\u001b[39md_head \u001b[38;5;28;01melse\u001b[39;00m res\u001b[38;5;241m+\u001b[39mpos\n\u001b[0;32m---> 88\u001b[0m     para_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(attn(compressed_res, compressed_res, compressed_res, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_mask)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m attn \u001b[38;5;129;01min\u001b[39;00m para_attn)\n\u001b[1;32m     89\u001b[0m     decompressed_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_decompress(para_res) \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m!=\u001b[39md_head \u001b[38;5;28;01melse\u001b[39;00m para_res\n\u001b[1;32m     90\u001b[0m     res \u001b[38;5;241m=\u001b[39m decompressed_res\u001b[38;5;241m.\u001b[39madd_(res) \n",
      "File \u001b[0;32m~/Desktop/Stage Dauphine Code/Learning_Bigram/models.py:88\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m para_attn, mlp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_seq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_seq):\n\u001b[1;32m     87\u001b[0m     compressed_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_compress(res) \u001b[38;5;241m+\u001b[39m pos \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m!=\u001b[39md_head \u001b[38;5;28;01melse\u001b[39;00m res\u001b[38;5;241m+\u001b[39mpos\n\u001b[0;32m---> 88\u001b[0m     para_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompressed_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompressed_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m attn \u001b[38;5;129;01min\u001b[39;00m para_attn)\n\u001b[1;32m     89\u001b[0m     decompressed_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_decompress(para_res) \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m!=\u001b[39md_head \u001b[38;5;28;01melse\u001b[39;00m para_res\n\u001b[1;32m     90\u001b[0m     res \u001b[38;5;241m=\u001b[39m decompressed_res\u001b[38;5;241m.\u001b[39madd_(res) \n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/leo_env/lib/python3.11/site-packages/torch/nn/functional.py:5403\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_causal \u001b[38;5;129;01mand\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFIXME: is_causal not implemented for need_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 5403\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaddbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5405\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Experiment 5. Scaling laws on the width of Transformer using MLPs. \"\"\"\n",
    "t.manual_seed(3333)\n",
    "\n",
    "# Model parameters.\n",
    "N = 50\n",
    "para = 1\n",
    "nb_layers = 5 # Depth of the network\n",
    "nb_head = 1\n",
    "n_gram = 3\n",
    "context_window = n_gram\n",
    "\n",
    "# Distribution parameters.\n",
    "alphas = [1, 1, 1]\n",
    "nb_tokens=[100, 100, 1]\n",
    "pi = power_unif_law(alphas, nb_tokens, N)\n",
    "\n",
    "# Training parameters.\n",
    "batch_size=2**11\n",
    "num_batch=2000\n",
    "lr=5e-4\n",
    "epochs=10\n",
    "repetition = 2\n",
    "Data = generate_data(batch_size=batch_size, num_batch=num_batch, pi=pi, context_window=context_window)\n",
    "\n",
    "for d, exp_num in zip([7, 10, 13], [4, 7, 10]):\n",
    "    d_head = d\n",
    "    min_width = 2*d*(1-1)\n",
    "    max_width = 2*d*(21-1)\n",
    "    step = 2*d*5\n",
    "\n",
    "    mean_accuracy = []\n",
    "    para_list = []\n",
    "    N_list = []\n",
    "    d_list = []\n",
    "    d_head_list = []\n",
    "    width_list = []\n",
    "    for width in tqdm(range(min_width, max_width+1, step)):\n",
    "        accuracy = 0\n",
    "\n",
    "        for _ in range(repetition):\n",
    "            model = Transformer(d, N, nb_layers, width, para, d_head, nb_head, context_window, pi)\n",
    "\n",
    "            dict = train(model, Data, epochs, lr=lr, next_token=True)\n",
    "            acc = sum(dict['Acc'][-101:-1])/100\n",
    "            \n",
    "            accuracy += acc\n",
    "            print(accuracy)\n",
    "\n",
    "        mean_accuracy.append(accuracy/repetition)\n",
    "        N_list.append(N)\n",
    "        d_list.append(d)\n",
    "        d_head_list.append(d_head)\n",
    "        para_list.append(para)\n",
    "        width_list.append(width)\n",
    "\n",
    "    results = {\n",
    "        'acc': mean_accuracy,\n",
    "        'para': para_list,\n",
    "        'N': N_list,\n",
    "        'd': d_list,\n",
    "        'd_head': d_head_list,\n",
    "        'width': width_list,\n",
    "    }\n",
    "\n",
    "    # We save the results as a dataframe.\n",
    "    data = pd.DataFrame(results)\n",
    "    data.to_csv(f'Scaling laws/Data_exp_5_{exp_num}_depth.csv', index=False)\n",
    "\n",
    "\n",
    "for d, exp_num in zip([7, 13], [4, 10]):\n",
    "    d_head = d\n",
    "    min_para = 1\n",
    "    max_para = 21\n",
    "    step = 5\n",
    "\n",
    "    mean_accuracy = []\n",
    "    para_list = []\n",
    "    N_list = []\n",
    "    d_list = []\n",
    "    d_head_list = []\n",
    "    width_list = []\n",
    "    for para in tqdm(range(min_para, max_para+1, step)):\n",
    "        accuracy = 0\n",
    "\n",
    "        for _ in range(repetition):\n",
    "            model = AoT(d, N, nb_layers, para, d_head, nb_head, context_window, pi)\n",
    "\n",
    "            dict = train(model, Data, epochs, lr=lr, next_token=True)\n",
    "            acc = sum(dict['Acc'][-101:-1])/100\n",
    "            \n",
    "            accuracy += acc\n",
    "            print(accuracy)\n",
    "\n",
    "        mean_accuracy.append(accuracy/repetition)\n",
    "        N_list.append(N)\n",
    "        d_list.append(d)\n",
    "        d_head_list.append(d_head)\n",
    "        para_list.append(para)\n",
    "        width_list.append(width)\n",
    "\n",
    "    results = {\n",
    "        'acc': mean_accuracy,\n",
    "        'para': para_list,\n",
    "        'N': N_list,\n",
    "        'd': d_list,\n",
    "        'd_head': d_head_list,\n",
    "        'width': width_list,\n",
    "    }\n",
    "\n",
    "    # We save the results as a dataframe.\n",
    "    data = pd.DataFrame(results)\n",
    "    data.to_csv(f'Scaling laws/Data_exp_1_{exp_num}_depth.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
